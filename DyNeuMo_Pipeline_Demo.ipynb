{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dbb2a72",
   "metadata": {},
   "source": [
    "## DyNeuMo-2 Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb850aa",
   "metadata": {},
   "source": [
    "This Jupyter Notebook integrates tools for setting up the configuration file for DyNeuMo-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e4bf59",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "#from IPython.core.interactiveshell import InteractiveShell\n",
    "#InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Load modules\n",
    "# Data handling and analysis modules -\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import signal, io\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from scipy.signal import spectrogram, periodogram, lfilter, freqz, iirfilter\n",
    "\n",
    "# Plotting modules\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Interactive plotting packages - \n",
    "import holoviews as hv\n",
    "from holoviews import opts, streams\n",
    "from holoviews.plotting.links import DataLink\n",
    "from holoviews.selection import link_selections\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "hv.extension(\"bokeh\", logo=False)\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.layouts import column, gridplot, layout\n",
    "from bokeh.models import BoxZoomTool, PanTool, ResetTool, HoverTool, WheelPanTool\n",
    "from bokeh.io import show, curdoc\n",
    "\n",
    "# For representing a datetime\n",
    "from datetime import datetime\n",
    "import dateutil.parser as dparser\n",
    "\n",
    "# For raising warnings\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import function for loading the DyNeuMo LFP data\n",
    "from read_Dyneumo_LFP_Format import read_Dyneumo_LFP_Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06290a9",
   "metadata": {},
   "source": [
    "## Step 0 - Load the DyNeuMo-2 Data File "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c213b5c",
   "metadata": {},
   "source": [
    "Any data file that is to analysed using the pipeline must be compliant with the structure of DyNeuMo-2 data. The pipeline should only accepts csv files which adhere to the DyNeuMo data format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converted Antonio data file path\n",
    "C:/Users/ndcm1133/OneDrive - Nexus365/Desktop/DyNeuMo_Software/DyNeuMo_Pipeline/DyNeuMo_2_Pipeline/Seizure_Data/Friday_Data/Seizure/Seizure_0/Channel_7.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d08488",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_Filepath_Text = pn.widgets.TextInput(name='DyNeuMo-2 Data Filepath', value='', placeholder='Enter filepath here ...', width=600, align='end')\n",
    "load_Data_Button = pn.widgets.Button(name='Load Data', button_type='primary', width=100, align='end')\n",
    "\n",
    "# Define dictionary for storing the loaded data\n",
    "LFP_Data = {}\n",
    "\n",
    "def on_Load_Data_Button_Clicked(b):\n",
    "    print(input_Filepath_Text.value)\n",
    "    \n",
    "    # Check if file exists\n",
    "    if os.path.isfile(input_Filepath_Text.value):\n",
    "        \n",
    "        #try: \n",
    "        # Load the data - need to pass the mark as a input\n",
    "        lfp = read_Dyneumo_LFP_Format(input_Filepath_Text.value, 2)\n",
    "\n",
    "        # Convert the raw LFP to a dataset\n",
    "        raw_LFP_data = {'Time': lfp['t'], 'Voltage': lfp['x']}\n",
    "        raw_LFP_dataframe = pd.DataFrame(data=raw_LFP_data)\n",
    "        LFP_Data['raw_LFP_Data'] = raw_LFP_dataframe\n",
    "        LFP_Data['sampling_Frequency'] = lfp['Fs']\n",
    "        \n",
    "        # Calculate the signal spectrogram\n",
    "        frequency, time, Sxx = spectrogram(raw_LFP_data['Voltage'], LFP_Data['sampling_Frequency'])\n",
    "        LFP_Spectrogram_ds = hv.Dataset((time, frequency, np.log10(Sxx)), ['Time', 'Frequency'], 'dB/Hz')\n",
    "        LFP_Data['raw_LFP_Spectrogram'] = LFP_Spectrogram_ds\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "    # Need to add error handling code here to check the data exists and is in the correct format\n",
    "    # \n",
    "    ############################################################################################\n",
    "\n",
    "\n",
    "# Connect the button widgets to their respective functions\n",
    "load_Data_Button.on_click(on_Load_Data_Button_Clicked)\n",
    "\n",
    "# Layout of the widgets\n",
    "load_Data_Row = pn.Row(input_Filepath_Text, load_Data_Button)\n",
    "load_Data_Row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3797616",
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf790ead",
   "metadata": {},
   "source": [
    "## Step 1 - Inspect the Loaded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c60c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve  [height=200 width=600, tools=['box_select', 'hover'], active_tools=[]]\n",
    "%%opts Curve (line_width=1.0)\n",
    "%%opts Histogram [height=200 width=300, tools=['hover'], active_tools=[]]\n",
    "\n",
    "# Plot the data as a curve\n",
    "raw_LFP_Trace = hv.Curve(LFP_Data['raw_LFP_Data'], 'Time', 'Voltage')\n",
    "\n",
    "# Calculate the histogram of the raw LFP\n",
    "hist_frequencies, hist_edges = np.histogram(LFP_Data['raw_LFP_Data']['Voltage']/1e-6, 50)\n",
    "\n",
    "# Normalize the histogram frequency as a percentage of the signal length\n",
    "percent_hist_frequencies = 100*(hist_frequencies/len(LFP_Data['raw_LFP_Data']['Voltage']))\n",
    "\n",
    "# Normalized histogram plot\n",
    "LFP_histogram = hv.Histogram((hist_edges, percent_hist_frequencies)).opts(xlabel='Signal Level (uV)', ylabel='Signal Distribution (%)')\n",
    "\n",
    "# Plot the spectrogram for the signal\n",
    "spectrogram_Plot = LFP_Data['raw_LFP_Spectrogram'].to(hv.Image, ['Time', 'Frequency']).opts(colorbar=True, cmap='viridis', ylim=(0, 60), title='LFP Spectrogram', xlabel='Time (s)', ylabel='Frequency (Hz)', clabel='dB/Hz', width=900, fontscale=1.2)\n",
    "\n",
    "# Plot the time series and histogram\n",
    "#raw_signal_Plots = hv.Layout((raw_LFP_Trace).opts(title=\"Raw LFP\", fontscale=1.2, xformatter='%d', yformatter='%.2e', width=600)  + (LFP_histogram).opts(ylim=(0, 20), xticks=[-0.0005, 0, 0.0005], title=\"LFP Histogram\", fontscale=1.2, xformatter='%.4f', yformatter='%d', width=300))\n",
    "#raw_signal_Plots = hv.Layout((raw_LFP_Trace).opts(title=\"Raw LFP\", fontscale=1.2, xformatter='%d', yformatter='%.2e', width=600)  + (LFP_histogram).opts(ylim=(0, 20), xticks=[np.min(LFP_Data['raw_LFP_Data']['Voltage']), 0, np.max(LFP_Data['raw_LFP_Data']['Voltage'])], title=\"LFP Histogram\", fontscale=1.2, xformatter='%.4e', yformatter='%d', width=300))\n",
    "raw_signal_Plots = hv.Layout((raw_LFP_Trace).opts(color='blue', title=\"Raw LFP\", fontscale=1.2, xformatter='%d', yformatter='%.2e', width=600)  + (LFP_histogram).opts(color='blue', ylim=(0, 20), title=\"LFP Histogram\", fontscale=1.2, xformatter='%.2e', yformatter='%d', width=300))\n",
    "raw_signal_Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928e72d9",
   "metadata": {},
   "source": [
    "## Step 1.1 - Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad3713",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve  [height=200 width=900 tools=['box_select', 'hover'], active_tools=[]]\n",
    "%%opts Curve (line_width=1.0)\n",
    "%opts Image  [height=300 width=900, tools=['box_select', 'hover'], active_tools=[]]\n",
    "\n",
    "# Inspect the spectrogram\n",
    "# Plot the time series and spectrogram\n",
    "time_frequency_layout = hv.Layout((raw_LFP_Trace).opts(title=\"Raw LFP\", fontscale=1.2, xaxis=None)  + (spectrogram_Plot).opts(title=\"LFP Spectrogram\", fontscale=1.2) ).cols(1)\n",
    "#time_frequency_layout = (spectrogram_Plot).opts(title=\"LFP Spectrogram\", fontscale=1.2)\n",
    "time_frequency_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efe3f48",
   "metadata": {},
   "source": [
    "## Step 2 - Event Data Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e331302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve  [height=200 width=900, tools=['box_select', 'hover'], active_tools=['box_select']]\n",
    "%%opts Curve (line_width=1.0)\n",
    "%%opts Image  [height=300 width=900, tools=['box_select', 'hover'], active_tools=['box_select']]\n",
    "%%opts VLine (color='red' line_dash='dashed')\n",
    "\n",
    "# Define region of interest indices as a list\n",
    "roi_indices = [-1, -1]\n",
    "\n",
    "# Function definition for marking the region of interest\n",
    "def mark_ROI(boundsx):\n",
    "    \n",
    "    # Set roi_indices as a global variable\n",
    "    global roi_indices \n",
    "    \n",
    "    # Set the roi indices to those input\n",
    "    roi_indices = [boundsx[0], boundsx[1]]\n",
    "    \n",
    "    # Highlight the roi as vertical lines\n",
    "    start_line = hv.VLine(boundsx[0]).opts(color='red', line_dash='dashed')\n",
    "    end_line = hv.VLine(boundsx[1]).opts(color='red', line_dash='dashed')\n",
    "    roi_markers = start_line * end_line\n",
    "    \n",
    "    return roi_markers\n",
    "\n",
    "# Define a dynamic map for highlighting the bounds of the region of interest\n",
    "#roi = hv.DynamicMap(mark_ROI, streams=[streams.BoundsX(source=raw_LFP_Trace, boundsx=(-1,-1))])\n",
    "roi = hv.DynamicMap(mark_ROI, streams=[streams.BoundsX(source=spectrogram_Plot, boundsx=(-1,-1))])\n",
    "\n",
    "# Add checkbox and button for data labelling\n",
    "dropdown_Label_Select = pn.widgets.Select(options=['event','not_event'], name='Data Segment Label')\n",
    "label_Segment_Button = pn.widgets.Button(name='Label Segment', button_type='primary', width=100, align='end')\n",
    "text = pn.widgets.TextInput(value='Data Segment - ', align='end')\n",
    "\n",
    "# Define dataframe for the regions of interest\n",
    "roi_segments_df = pd.DataFrame(columns=['Event_Type', 'Start_Time', 'End_Time'])\n",
    "\n",
    "# For loading events\n",
    "load_Events_Input_Filepath_Text = pn.widgets.TextInput(name='Event Labels Filepath', value='', placeholder='Enter filepath here ...', width=600, align='end')\n",
    "load_Event_Labels_Button = pn.widgets.Button(name='Load Events', button_type='primary', width=100, align='end')\n",
    "\n",
    "input_labels = []\n",
    "\n",
    "# Function to load events from file highlighted segment to dataframe\n",
    "def load_Events(event):\n",
    "    \n",
    "    # Define access to global variable elements\n",
    "    global roi_segments_df\n",
    "    global roi_indices \n",
    "    global input_labels\n",
    "    \n",
    "    # load the specified labels file\n",
    "    event_labels_file = load_Events_Input_Filepath_Text.value\n",
    "    event_labels_file.replace('\\\\', '/')\n",
    "    event_labels_data = np.loadtxt(event_labels_file, delimiter=',')\n",
    "    \n",
    "    # For debugging - \n",
    "    input_labels = event_labels_data\n",
    "    \n",
    "    # Check for when the signal changes - 0 -> 1 for start of event, 1 -> 0 for end of event\n",
    "    delta_event_labels = np.diff(event_labels_data, prepend=np.array([0]))\n",
    "    event_start_indices = np.where(delta_event_labels == 1)[0]\n",
    "    event_end_indices = np.where(delta_event_labels == -1)[0]\n",
    "    \n",
    "    # Append event labels to dataframe\n",
    "    for event_id in np.arange(0, len(event_start_indices), 1):\n",
    "        \n",
    "        # Add the new data segment to the roi segments dataframe\n",
    "        new_row = {'Event_Type': 'event', 'Start_Time': LFP_Data['raw_LFP_Data']['Time'][event_start_indices[event_id]], 'End_Time': LFP_Data['raw_LFP_Data']['Time'][event_end_indices[event_id]]}\n",
    "        roi_segments_df = roi_segments_df.append(new_row, ignore_index=True)\n",
    "\n",
    "    # Update text box text \n",
    "    text.value = 'Loaded Events!'\n",
    "    \n",
    "    return text.value\n",
    "\n",
    "# Function to append highlighted segment to dataframe\n",
    "def append_segment(event):\n",
    "    \n",
    "    # Define access to global variable elements\n",
    "    global roi_segments_df\n",
    "    global roi_indices \n",
    " \n",
    "    # Add the new data segment to the roi segments dataframe\n",
    "    new_row = {'Event_Type': dropdown_Label_Select.value, 'Start_Time': roi_indices[0], 'End_Time': roi_indices[1]}\n",
    "    roi_segments_df = roi_segments_df.append(new_row, ignore_index=True)\n",
    "    \n",
    "    # Update text box text \n",
    "    text.value = '{0} = ({1} - {2}) s'.format(dropdown_Label_Select.value, roi_indices[0], roi_indices[1])\n",
    "    \n",
    "    return text.value\n",
    "\n",
    "# Trigger when button is clicked\n",
    "label_Segment_Button.on_click(append_segment)\n",
    "load_Event_Labels_Button.on_click(load_Events)\n",
    "\n",
    "# Put data panels together\n",
    "time_frequency_events_layout = pn.Column(hv.Layout((raw_LFP_Trace * roi).opts(height=200, width=900, title=\"Raw LFP\", fontscale=1.2, xaxis=None) + (spectrogram_Plot * roi).opts(title=\"LFP Spectrogram\", fontscale=1.2)).cols(1), pn.Row(load_Events_Input_Filepath_Text, load_Event_Labels_Button), pn.Row(dropdown_Label_Select, label_Segment_Button, text))\n",
    "#time_frequency_events_layout = pn.Column((spectrogram_Plot * roi).opts(title=\"LFP Spectrogram\", fontscale=1.2), pn.Row(load_Events_Input_Filepath_Text, load_Event_Labels_Button), pn.Row(dropdown_Label_Select, label_Segment_Button, text))\n",
    "time_frequency_events_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab771204",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_segments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a6157",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Curve  [height=450 width=650, tools=['box_select', 'hover'], active_tools=[]]\n",
    "%%opts VLine (color='black' line_dash='dashed')\n",
    "\n",
    "# Get the event labels\n",
    "event_Labels = pd.unique(roi_segments_df['Event_Type'])\n",
    "\n",
    "# Dictionary for storing the labelled data snippets\n",
    "event_segments = {}\n",
    "max_data_segment_length = 0\n",
    "\n",
    "# Set up array of potential data labels\n",
    "user_defined_labels = np.zeros(len(LFP_Data['raw_LFP_Data']['Time']))\n",
    "\n",
    "# Parse the roi dataframe into a dictionary for each event\n",
    "for event_Label in event_Labels:\n",
    "    \n",
    "    # Extract the start and end times for each event roi as a list\n",
    "    event_dataframes = {}\n",
    "    event_table = roi_segments_df.loc[roi_segments_df['Event_Type'] == event_Label][['Start_Time', 'End_Time']]\n",
    "    event_dataframes[event_Label] = event_table.values.tolist()\n",
    "    \n",
    "    # Add event snippet to the dictionary \n",
    "    event_segments[event_Label] = []\n",
    "    \n",
    "    # Increment through each event to pull the associated snipped of data\n",
    "    for event_index in np.arange(0, len(event_dataframes[event_Label]), 1):\n",
    "    \n",
    "        snippet_start_id = (LFP_Data['raw_LFP_Data']['Time'] - event_dataframes[event_Label][event_index][0]).abs().argsort()[0]\n",
    "        snippet_end_id = (LFP_Data['raw_LFP_Data']['Time'] - event_dataframes[event_Label][event_index][1]).abs().argsort()[0]\n",
    "\n",
    "        # if event_Label is 'event' then set indices identified to 1\n",
    "        if event_Label == 'event':\n",
    "            user_defined_labels[snippet_start_id:snippet_end_id] = 1\n",
    "        \n",
    "        # Pull this snippet then from the original data dataframe\n",
    "        event_data_snippet = {'Time': LFP_Data['raw_LFP_Data']['Time'][snippet_start_id:snippet_end_id] , 'Voltage': LFP_Data['raw_LFP_Data']['Voltage'][snippet_start_id:snippet_end_id]}\n",
    "\n",
    "        # Add event snippet to the dictionary \n",
    "        event_segments[event_Label].append(event_data_snippet)\n",
    "\n",
    "        # Also calculate the length of the segment so can zero to length of longest segment later for PSD\n",
    "        if len(event_data_snippet['Time']) > max_data_segment_length:\n",
    "            max_data_segment_length = len(event_data_snippet['Time'])\n",
    "        \n",
    "        \n",
    "# Function to append highlighted segment to dataframe\n",
    "def calculate_PSD(x, Fs, max_segment_length):\n",
    "    \n",
    "    if len(x) < max_segment_length:\n",
    "        x = np.hstack((x, np.zeros(max_segment_length - len(x))))\n",
    "        \n",
    "    f, Pxx_den = signal.welch(x, Fs, nperseg=1024)\n",
    "    \n",
    "    return f, Pxx_den\n",
    "        \n",
    "def calculate_Event_PSDs(event_segments, event_Labels, Fs, max_segment_length):\n",
    "    \n",
    "    # Create dictionary for the storing the PSD for each event\n",
    "    event_PSDs = {}\n",
    "    \n",
    "    # Go through the event labels\n",
    "    for event_Label in event_Labels:\n",
    "        \n",
    "        # Add event label to the PSD dictionary \n",
    "        event_PSDs[event_Label] = []\n",
    "    \n",
    "        # Increment through each event snippet and calculate it's PSD\n",
    "        for index in np.arange(0, len(event_segments[event_Label]), 1):\n",
    "            \n",
    "            # Calculate the event PSD\n",
    "            snippet_f, snippet_Pxx_den = calculate_PSD(event_segments[event_Label][index]['Voltage'], Fs, max_segment_length)\n",
    "            \n",
    "            # Normalize the PSD by the total power for the snippet across the frequencies\n",
    "            snippet_Pxx_den_dB = 10*np.log10(snippet_Pxx_den)\n",
    "            snippet_Pxx_den_dB\n",
    "            total_Pxx_dB = np.sum(snippet_Pxx_den_dB)\n",
    "            \n",
    "            # Pull this snippet then from the original data dataframe\n",
    "            event_PSD = {'Frequency': snippet_f, 'Pxx': snippet_Pxx_den_dB}\n",
    "        \n",
    "            # Add event snippet to the dictionary \n",
    "            event_PSDs[event_Label].append(event_PSD)\n",
    "            \n",
    "    return event_PSDs\n",
    "\n",
    "# Calculate all the event PSDs\n",
    "event_PSDs = calculate_Event_PSDs(event_segments, event_Labels, LFP_Data['sampling_Frequency'], max_data_segment_length)\n",
    "\n",
    "# Generate the cumulative PSDs for each event\n",
    "event_cumulative_PSDs = {}\n",
    "\n",
    "for event_Label in event_Labels: \n",
    "    event_PSD_HoloMap = hv.HoloMap({i: hv.Curve(event_PSDs[event_Label][i], 'Frequency', 'Pxx') for i in range(len(event_PSDs[event_Label]))})\n",
    "    cumulative_event_PSD = event_PSD_HoloMap.collapse(function=np.mean, spreadfn=np.std)\n",
    "    event_cumulative_PSDs[event_Label] = cumulative_event_PSD\n",
    "    \n",
    "# Plot the cumulative power spectra  \n",
    "for index in np.arange(0, len(event_cumulative_PSDs), 1):\n",
    "    if index == 0:\n",
    "#        cumulative_PSD_Figure = hv.Spread(event_cumulative_PSDs[event_Labels[index]]) * (hv.Curve(event_cumulative_PSDs[event_Labels[index]], label=event_Label))\n",
    "        cumulative_PSD_Figure = hv.Curve(event_cumulative_PSDs[event_Labels[index]], label=event_Label)\n",
    "    else:\n",
    "#        cumulative_PSD_Figure = cumulative_PSD_Figure * hv.Spread(event_cumulative_PSDs[event_Labels[index]]) * hv.Curve(event_cumulative_PSDs[event_Labels[index]], label=event_Label)\n",
    "                cumulative_PSD_Figure = cumulative_PSD_Figure * hv.Curve(event_cumulative_PSDs[event_Labels[index]], label=event_Label)\n",
    "    \n",
    "# Define region of interest indices as a list\n",
    "frequency_band_roi_indices = [-1, -1]\n",
    "\n",
    "# Function definition for marking the frequency band region of interest\n",
    "def mark_Frequency_Band_ROI(boundsx):\n",
    "    \n",
    "    # Set roi_indices as a global variable\n",
    "    global frequency_band_roi_indices \n",
    "    \n",
    "    # Set the roi indices to those input\n",
    "    frequency_band_roi_indices = [boundsx[0], boundsx[1]]\n",
    "    \n",
    "    # Highlight the roi as vertical lines\n",
    "    start_line = hv.VLine(boundsx[0])\n",
    "    end_line = hv.VLine(boundsx[1])\n",
    "    frequency_Band_roi_markers = start_line * end_line\n",
    "    \n",
    "    return frequency_Band_roi_markers    \n",
    "\n",
    "# Set up dynamic map for marking the frequency band of interest\n",
    "frequency_Band_roi = hv.DynamicMap(mark_Frequency_Band_ROI, streams=[streams.BoundsX(source=cumulative_PSD_Figure, boundsx=(-1,-1))])\n",
    "\n",
    "# Plot the cumulative Power Spectra for the events\n",
    "cumulative_PSD_with_ROI_Figure = (cumulative_PSD_Figure * frequency_Band_roi).opts(xlim=(0,LFP_Data['sampling_Frequency']/2.0), ylabel='dB/Hz', xlabel='Frequency (Hz)', title=\"Cumulative Event Power Spectra\", fontscale=1.5, show_legend=True)\n",
    "cumulative_PSD_with_ROI_Figure\n",
    "\n",
    "# Add text box and buttons for exporting data labels and bandpass cutoff frequencies\n",
    "event_Labels_filename = pn.widgets.TextInput(value='', placeholder='Enter Event Labels Filename ...', width=500, align='end')\n",
    "export_Data_Labels_Button = pn.widgets.Button(name='Export Labels', button_type='primary', width=100, align='end')\n",
    "load_Data_Labels_Button = pn.widgets.Button(name='Load Labels', button_type='primary', width=100, align='end')\n",
    "extract_Cutoff_Frequencies_Button = pn.widgets.Button(name='Extract Bandpass Fc', button_type='primary', width=100, align='end')\n",
    "\n",
    "# Function to save the data labels to a csv file\n",
    "def export_Data_Labels(event):\n",
    "    \n",
    "    # Save the user defined labels array of 1s (event) and 0s (not_event) to a csv file\n",
    "    np.savetxt(event_Labels_filename.value, user_defined_labels, delimiter=\",\")\n",
    "    LFP_Data['raw_LFP_Data']['Data_Labels'] = user_defined_labels\n",
    "    \n",
    "# Trigger export data labels when button is clicked\n",
    "export_Data_Labels_Button.on_click(export_Data_Labels)\n",
    "\n",
    "# Function to load the data labels to a csv file\n",
    "def load_Data_Labels(event):\n",
    "    \n",
    "    global LFP_Data\n",
    "    \n",
    "    # Load the user defined labels array of 1s (event) and 0s (not_event) to a csv file\n",
    "    label_filename = event_Labels_filename.value\n",
    "    label_filename.replace('\\\\', '/')\n",
    "    user_defined_labels = np.loadtxt(label_filename, delimiter=\",\")\n",
    "    LFP_Data['raw_LFP_Data']['Data_Labels'] = user_defined_labels\n",
    "    \n",
    "# Trigger export data labels when button is clicked\n",
    "load_Data_Labels_Button.on_click(load_Data_Labels)\n",
    "\n",
    "bandpass_cutoff_frequencies = [-1, -1]\n",
    "\n",
    "# Function to save the data labels to a csv file\n",
    "def extract_Cutoff_Frequencies(event):\n",
    "    \n",
    "    global bandpass_cutoff_frequencies\n",
    "    global frequency_band_roi_indices\n",
    "    \n",
    "    # Update the frequencies that'll be used for the bandpass filter\n",
    "    bandpass_cutoff_frequencies = [frequency_band_roi_indices[0], frequency_band_roi_indices[1]]\n",
    "    \n",
    "# Trigger export data labels when button is clicked\n",
    "extract_Cutoff_Frequencies_Button.on_click(extract_Cutoff_Frequencies)\n",
    "\n",
    "#pn.Row(event_Labels_filename, load_Data_Labels_Button, export_Data_Labels_Button, extract_Cutoff_Frequencies_Button)\n",
    "cumulative_PSD_with_ROI_Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac7303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(event_Labels_filename, load_Data_Labels_Button, export_Data_Labels_Button, extract_Cutoff_Frequencies_Button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30abf1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input labels\n",
    "C:/Users/ndcm1133/OneDrive - Nexus365/Desktop/DyNeuMo_Software/DyNeuMo_Pipeline/DyNeuMo_2_Pipeline/Seizure_Data/Friday_Data/Seizure/Seizure_0/user_Event_Labels.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431312c7",
   "metadata": {},
   "source": [
    "## Step 3 - Filter Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f95a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve  [height=450 width=450, tools=['box_select', 'hover'], active_tools=[]]\n",
    "\n",
    "# Function for generating filter co-efficients\n",
    "def iir_butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = iirfilter(order, [low, high], btype='band', analog=False, ftype='butter')\n",
    "    return b, a\n",
    "\n",
    "# Function for generating filter co-efficients\n",
    "def iir_butter_lowpass(lowcut, fs, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    b, a = iirfilter(order, low, btype='low', analog=False, ftype='butter')\n",
    "    return b, a\n",
    "\n",
    "# Bandpass filter cutoff frequencies\n",
    "#bandpass_lowcut = 8.0        # low cutoff frequency\n",
    "#bandpass_highcut = 13.0      # high cutoff frequency\n",
    "bandpass_lowcut = np.floor(bandpass_cutoff_frequencies[0])\n",
    "bandpass_highcut = np.ceil(bandpass_cutoff_frequencies[1])\n",
    "bandpass_filter_order = 3\n",
    "\n",
    "# Lowpass filter cutoff frequency - for envelope extraction\n",
    "lowpass_cutoff = 1.0        # low cutoff frequency\n",
    "lowpass_filter_order = 2\n",
    "\n",
    "# Plot the frequency response for a few different orders.\n",
    "bandpass_b, bandpass_a = iir_butter_bandpass(bandpass_lowcut, bandpass_highcut, LFP_Data['sampling_Frequency'], order=bandpass_filter_order)\n",
    "bandpass_w, bandpass_h = freqz(bandpass_b, bandpass_a, worN=2000)\n",
    "bandpass_filter_data = {'Frequency': (LFP_Data['sampling_Frequency'] * 0.5 / np.pi) * bandpass_w, 'Magnitude': 20.0*np.log10(abs(bandpass_h))}\n",
    "bandpass_filter_dataframe = pd.DataFrame(data=bandpass_filter_data)\n",
    "bandpass_cutoff_frequency_bounds = {'Frequency': [bandpass_lowcut, bandpass_lowcut, bandpass_highcut, bandpass_highcut], 'Magnitude': [-1e3, 0, 0, -1e3]}\n",
    "bandpass_cutoff_frequency_dataframe = pd.DataFrame(data=bandpass_cutoff_frequency_bounds)\n",
    "\n",
    "# Plot the frequency response of the lowpass filter.\n",
    "lowpass_b, lowpass_a = iir_butter_lowpass(lowpass_cutoff, LFP_Data['sampling_Frequency'], order=lowpass_filter_order)\n",
    "lowpass_w, lowpass_h = freqz(lowpass_b, lowpass_a, worN=2000)\n",
    "lowpass_filter_data = {'Frequency': (LFP_Data['sampling_Frequency'] * 0.5 / np.pi) * lowpass_w, 'Magnitude': 20.0*np.log10(abs(lowpass_h))}\n",
    "lowpass_filter_dataframe = pd.DataFrame(data=lowpass_filter_data)\n",
    "lowpass_cutoff_frequency_bounds = {'Frequency': [0, lowpass_cutoff, lowpass_cutoff], 'Magnitude': [0, 0, -1e3]}\n",
    "lowpass_cutoff_frequency_dataframe = pd.DataFrame(data=lowpass_cutoff_frequency_bounds)\n",
    "\n",
    "# Plot the filter response as a curve\n",
    "bandpass_filter_response_Trace = hv.Curve(bandpass_filter_dataframe, 'Frequency', 'Magnitude')\n",
    "bandpass_filter_cutoff_frequencies_Trace = hv.Curve(bandpass_cutoff_frequency_dataframe, 'Frequency', 'Magnitude').opts(line_dash='dashed')\n",
    "\n",
    "bandpass_filter_layout_Figure = ((bandpass_filter_response_Trace) * (bandpass_filter_cutoff_frequencies_Trace)).opts(fontscale=1.2, title='Bandpass Filter Response', xlabel='Frequency (Hz)', ylabel='Magnitude (dB)', ylim=(-300, 10))\n",
    "\n",
    "# Plot the filter response as a curve\n",
    "lowpass_filter_response_Trace = hv.Curve(lowpass_filter_dataframe, 'Frequency', 'Magnitude')\n",
    "lowpass_filter_cutoff_frequencies_Trace = hv.Curve(lowpass_cutoff_frequency_dataframe, 'Frequency', 'Magnitude').opts(line_dash='dashed')\n",
    "\n",
    "lowpass_filter_layout_Figure = ((lowpass_filter_response_Trace) * (lowpass_filter_cutoff_frequencies_Trace)).opts(fontscale=1.2, title='Smoothing Filter Response', xlabel='Frequency (Hz)', ylabel='Magnitude (dB)', ylim=(-300, 10))\n",
    "filter_Responses = bandpass_filter_layout_Figure + lowpass_filter_layout_Figure\n",
    "filter_Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7506cd0",
   "metadata": {},
   "source": [
    "## Step 4 - Bandpass Filter Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve  [height=200 width=900, tools=['box_select', 'hover'], active_tools=[]]\n",
    "%%opts Curve (color='blue' line_width=1.0)\n",
    "\n",
    "# Filter the signal using the filter co-efficients from the previous section\n",
    "bandpass_filtered_signal = lfilter(bandpass_b, bandpass_a, LFP_Data['raw_LFP_Data']['Voltage'])\n",
    "\n",
    "# Add the bandpass filtered signal to the LFP dataframe\n",
    "LFP_Data['raw_LFP_Data']['bandpass_Filtered_Signal'] = bandpass_filtered_signal\n",
    "\n",
    "# Plot the data as a curve\n",
    "filtered_LFP_Trace = hv.Curve(LFP_Data['raw_LFP_Data'], 'Time', 'bandpass_Filtered_Signal')\n",
    "#filtered_LFP_Trace\n",
    "\n",
    "# Plot the data labels as a curve\n",
    "data_Labels_Trace = hv.Curve(LFP_Data['raw_LFP_Data'], 'Time', 'Data_Labels')\n",
    "\n",
    "figure_layout = hv.Layout(filtered_LFP_Trace.opts(title=\"{:.0f} - {:.0f} Hz Bandpass Filtered Signal\".format(bandpass_lowcut, bandpass_highcut), ylabel='Voltage', xaxis=None, fontscale=1.2) + data_Labels_Trace.opts(title=\"Class Labels\", ylabel=\"Label\", fontscale=1.2, color='red', yticks=[(0, 'Not Event'), (1, 'Event')])).cols(1)\n",
    "figure_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f37e0",
   "metadata": {},
   "source": [
    "## Step 5 - Envelope Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b67c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve  [height=200 width=900, tools=['box_select', 'hover'], active_tools=[]]\n",
    "%%opts Curve (color='blue' line_width=1.0)\n",
    "\n",
    "# Rectify the bandpass filtered signal\n",
    "rectified_Filtered_Signal = np.abs(LFP_Data['raw_LFP_Data']['bandpass_Filtered_Signal']) \n",
    "\n",
    "# Add the rectified filtered signal to the LFP dataframe\n",
    "LFP_Data['raw_LFP_Data']['rectified_Filtered_Signal'] = rectified_Filtered_Signal\n",
    "\n",
    "# Lowpass filter the bandpass rectified LFP signal to extract envelope\n",
    "signal_Envelope = lfilter(lowpass_b, lowpass_a, LFP_Data['raw_LFP_Data']['rectified_Filtered_Signal'])\n",
    "\n",
    "# Add the signal envelope (lowpass filtered rectified bandpass filtered signal) to the LFP dataframe\n",
    "LFP_Data['raw_LFP_Data']['signal_Envelope'] = signal_Envelope\n",
    "\n",
    "# Bandpass filtered signal plot - \n",
    "filtered_LFP_Trace = hv.Curve(LFP_Data['raw_LFP_Data'], 'Time', 'bandpass_Filtered_Signal')\n",
    "\n",
    "# Rectified Bandpass filtered signal plot - \n",
    "rectified_filtered_LFP_Trace = hv.Curve(LFP_Data['raw_LFP_Data'], 'Time', 'rectified_Filtered_Signal')\n",
    "\n",
    "# Signal envelope plot - \n",
    "signal_Envelope_LFP_Trace = hv.Curve(LFP_Data['raw_LFP_Data'], 'Time', 'signal_Envelope')\n",
    "\n",
    "# Data labels as a curve\n",
    "data_Labels_Trace = hv.Curve(LFP_Data['raw_LFP_Data'], 'Time', 'Data_Labels')\n",
    "\n",
    "figure_layout = hv.Layout(filtered_LFP_Trace.opts(title=\"{:.0f} - {:.0f} Hz Bandpass Filtered Signal\".format(bandpass_lowcut, bandpass_highcut), ylabel='Voltage', xaxis=None, fontscale=1.2) + rectified_filtered_LFP_Trace.opts(title=\"Rectified Filtered Signal\", ylabel='Voltage', xaxis=None, fontscale=1.2) + signal_Envelope_LFP_Trace.opts(title=\"Bandpass Filtered Signal Envelope\", ylabel='Voltage', xaxis=None, fontscale=1.2) + data_Labels_Trace.opts(fontscale=1.2, title=\"Class Labels\", color='red', ylabel='Label', yticks=[(0, 'Open'), (1, 'Closed')])).cols(1)\n",
    "figure_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7cc5f2",
   "metadata": {},
   "source": [
    "## Step 6 - Calculate the ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create threshold vector with a fine grid\n",
    "min_threshold = 0\n",
    "#max_threshold = 0.3e-6\n",
    "max_threshold = 1.25e-5\n",
    "potential_Thresholds = np.linspace(min_threshold, max_threshold, 1000)\n",
    "\n",
    "# Create an array for the classifications of each threshold\n",
    "classRes = np.zeros((len(LFP_Data['raw_LFP_Data']['signal_Envelope']), len(potential_Thresholds)))\n",
    "\n",
    "# Increment through the different thresholds and make an initial check whether \n",
    "# the value is above or below the threshold. A class of 1 represents the alpha state\n",
    "for j in np.arange(0, len(potential_Thresholds)):\n",
    "\n",
    "    # Get the threshold value\n",
    "    threshold_value = potential_Thresholds[j]\n",
    "    \n",
    "    # Check which signal values are above the threshold\n",
    "    positive_classification_ids = np.where(LFP_Data['raw_LFP_Data']['signal_Envelope'] >= threshold_value)[0]\n",
    "    classRes[positive_classification_ids, j] = 1\n",
    "    \n",
    "#Now compare classifications for each threshold with the actual labels\n",
    "truth = LFP_Data['raw_LFP_Data']['Data_Labels']\n",
    "\n",
    "#               |         Classifier output\n",
    "#   True state  |  Alpha state = 0  |  Alpha state = 1  \n",
    "# ------------------------------------------------------\n",
    "#   Eyes open   | True Negative  TN | False Positive FP\n",
    "#  Eyes closed  | False Negative FN | True Positive  TP\n",
    "\n",
    "# Calculate TP, TN, FP, FN values\n",
    "tp = np.zeros(len(potential_Thresholds))\n",
    "tn = np.zeros(len(potential_Thresholds))\n",
    "fp = np.zeros(len(potential_Thresholds))\n",
    "fn = np.zeros(len(potential_Thresholds))\n",
    "\n",
    "# Loop over the thresholds and calculate the corresponding values\n",
    "for j in np.arange(0, len(potential_Thresholds)):\n",
    "    \n",
    "    # For postive classifications, check the number of true positives and false negatives\n",
    "    positive_classification_ids = np.where(truth == 1)[0]\n",
    "    \n",
    "    # Total True Positives - \n",
    "    true_positives_ids = np.where(classRes[positive_classification_ids, j] == 1)[0]  \n",
    "    tp[j] = len(true_positives_ids)\n",
    "    \n",
    "    # Total False Negatives - \n",
    "    false_negative_ids = np.where(classRes[positive_classification_ids, j] == 0)[0]\n",
    "    fn[j] = len(false_negative_ids)\n",
    "    \n",
    "    # For negative classifications, check the number of true negatives and false positives\n",
    "    negative_classification_ids = np.where(truth == 0)[0]\n",
    "    \n",
    "    # Total True Negatives - \n",
    "    true_negatives_ids = np.where(classRes[negative_classification_ids, j] == 0)[0]  \n",
    "    tn[j] = len(true_negatives_ids)\n",
    "    \n",
    "    # Total False Positives - \n",
    "    false_positive_ids = np.where(classRes[negative_classification_ids, j] == 1)[0]\n",
    "    fp[j] = len(false_positive_ids)\n",
    "\n",
    "\n",
    "# Create true positive rate (TPR) and false positive rate (TPR) vectors\n",
    "tpr = np.zeros(len(potential_Thresholds))\n",
    "fpr = np.zeros(len(potential_Thresholds))\n",
    "\n",
    "# Create precision and recall vectors\n",
    "#precision = np.zeros(len(potential_Thresholds))\n",
    "#recall = np.zeros(len(potential_Thresholds))\n",
    "\n",
    "# Now find the true positive rate and false positive rate for each threshold\n",
    "for j in np.arange(0, len(potential_Thresholds)):\n",
    "    # True positive rate (sensitivity)\n",
    "    # i.e. probability that a true positive is classified as positive\n",
    "    # TPR = TP / (TP + FN)\n",
    "    tpr[j] = tp[j] / (tp[j] + fn[j])\n",
    "\n",
    "    # False positive rate (1-specificity)\n",
    "    # probability that a true negative is classified as positive\n",
    "    # FPR = FP / (FP + TN)\n",
    "    fpr[j] = fp[j] / (fp[j] + tn[j])\n",
    "    \n",
    "    # Precision - \n",
    "    # precision = TP / (TP + FP)\n",
    "    #precision[j] = tp[j] / (tp[j] + fp[j])\n",
    "    \n",
    "    # Recall - \n",
    "    # recall = TP / (TP + FN)\n",
    "    #recall[j] = tp[j] / (tp[j] + fn[j])\n",
    "\n",
    "# ROC curve dataset\n",
    "ROC_ds = hv.Dataset((fpr, tpr, potential_Thresholds), ['FPR', 'TPR'], 'Threshold')\n",
    "\n",
    "# Precision-Recall curve dataset\n",
    "#precision_recall_ds = hv.Dataset((precision, recall, potential_Thresholds), ['Precision', 'Recall'], 'Threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1765e48d",
   "metadata": {},
   "source": [
    "## Step 5.1 - Plot the ROC Curve and Select the Classifier Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b69a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC Curve\n",
    "ROC_Curve_data = {'FPR': fpr, 'TPR': tpr, 'Threshold': potential_Thresholds}\n",
    "ROC_dataframe = pd.DataFrame(data=ROC_Curve_data)\n",
    "\n",
    "# Plot for the ROC curve\n",
    "ROC_Trace = hv.Curve(ROC_dataframe, 'FPR', 'TPR').opts(tools=['hover', 'tap'], line_dash='solid')\n",
    "naive_Trace = hv.Curve(ROC_dataframe, 'FPR', 'FPR').opts(line_dash='dashed')\n",
    "\n",
    "# Stream for detecting double-clicks\n",
    "ROC_click_Stream = hv.streams.DoubleTap(source=ROC_Trace, x=-10, y=-10, transient=True)\n",
    "\n",
    "# Threshold of user selected threshold for classifier\n",
    "ROC_selected_threshold = -10\n",
    "\n",
    "# Function definition for marking the region of interest\n",
    "def mark_ROC_Threshold(x, y):\n",
    "    \n",
    "    # Define that the selected threshold is global\n",
    "    global ROC_selected_threshold\n",
    "    \n",
    "    # Highlight the threshold as a horizontal line\n",
    "    y_threshold_line = hv.HLine(y).opts(color='black', line_dash='dashed')\n",
    "    \n",
    "    # Find the closest value to the y horizontal line\n",
    "    ROC_y_threshold_id = (ROC_dataframe['TPR'] - y).abs().argsort()[0]\n",
    "    \n",
    "    # Set the Vertical line as the closest TPR to the intersection point\n",
    "    x_threshold_value = ROC_dataframe['FPR'][ROC_y_threshold_id]\n",
    "    x_threshold_line = hv.VLine(x_threshold_value).opts(color='black', line_dash='dashed')\n",
    "    \n",
    "    # Intersection point\n",
    "    intersection_point = hv.Scatter((x_threshold_value, y)).opts(color='red', size=8)\n",
    "    \n",
    "    # Update the selected threshold\n",
    "    ROC_selected_threshold = ROC_dataframe['Threshold'][ROC_y_threshold_id]\n",
    "    \n",
    "    # Text to indicate the Threshold value\n",
    "    text = hv.Text(x_threshold_value+0.05, y, \"Threshold = {:.3e} V [FPR={:.2f}, TPR={:.2f}]\".format(ROC_selected_threshold, x_threshold_value, y), halign='left', valign='bottom')\n",
    "    \n",
    "    return x_threshold_line * y_threshold_line * intersection_point * text\n",
    "\n",
    "# Declare pointer stream initializing at (0, 0) and linking to ROC_Trace\n",
    "ROC_pointer_Stream = streams.PointerXY(x=0, y=0, source=ROC_Trace)\n",
    "\n",
    "# Function definition for marking the region of interest\n",
    "def hover_ROC_Threshold(x, y):\n",
    "    \n",
    "    # Highlight the threshold as a horizontal line\n",
    "    y_threshold_line = hv.HLine(y).opts(color='black', line_dash='solid')\n",
    "    \n",
    "    # Find the closest value to the y horizontal line\n",
    "    ROC_y_threshold_id = (ROC_dataframe['TPR'] - y).abs().argsort()[0]\n",
    "    \n",
    "    # Set the Vertical line as the closest TPR to the intersection point\n",
    "    x_threshold_value = ROC_dataframe['FPR'][ROC_y_threshold_id]\n",
    "    x_threshold_line = hv.VLine(x_threshold_value).opts(color='black', line_dash='solid')\n",
    "    \n",
    "    # Intersection point\n",
    "    intersection_point = hv.Scatter((x_threshold_value, y)).opts(color='black', size=6)\n",
    "    \n",
    "    # Update the selected threshold\n",
    "    selected_threshold = ROC_dataframe['Threshold'][ROC_y_threshold_id]\n",
    "    \n",
    "    # Text to indicate the Threshold value\n",
    "    text = hv.Text(x_threshold_value+0.05, y, \"Threshold = {:.3e} V [FPR={:.2f}, TPR={:.2f}]\".format(selected_threshold, x_threshold_value, y), halign='left', valign='bottom')\n",
    "    \n",
    "    return x_threshold_line * y_threshold_line * intersection_point * text\n",
    "\n",
    "# Set up dynamic map for tracking double-clicking on the plot\n",
    "ROC_Threshold_Double_Click_dmap = hv.DynamicMap(mark_ROC_Threshold, streams=[ROC_click_Stream])\n",
    "ROC_Threshold_Hover_dmap = hv.DynamicMap(hover_ROC_Threshold, streams=[ROC_pointer_Stream])\n",
    "\n",
    "# Plot for the ROC curve - \n",
    "(ROC_Trace * ROC_Threshold_Double_Click_dmap * naive_Trace).opts(fontscale=1.5, height=450, width=550, title='ROC Curve', xlabel='False Positive Rate (FPR)', ylabel='True Positive Rate (TPR)', xlim=(0,1), ylim=(0,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a1dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve  [height=300 width=900, tools=['hover', 'tap'], active_tools=[]]\n",
    "%%opts Scatter (color='k' alpha=0 fill_alpha=0 size=10)\n",
    "%%opts HLine (color='black' line_dash='dashed')\n",
    "\n",
    "# Function definition for marking the region of interest\n",
    "def mark_Threshold(x, y):\n",
    "    \n",
    "    # Highlight the threshold as a horizontal line\n",
    "    threshold_line = hv.HLine(y)\n",
    "    \n",
    "    # Calculate the output of the classifier with the selected threshold\n",
    "    new_classifer_labels = np.zeros(len(LFP_dataframe['signal_Envelope']))\n",
    "    positive_classification_ids = np.where(LFP_dataframe['signal_Envelope'] > y)[0]\n",
    "    \n",
    "    # Check if the new classifier should be initialized or actually plotted\n",
    "    if y < 0:\n",
    "        new_classifer_labels[positive_classification_ids] = -10\n",
    "    else:\n",
    "        new_classifer_labels[positive_classification_ids] = 1 * np.max(LFP_dataframe['rescaled_Data_Labels'])\n",
    "\n",
    "    time = LFP_dataframe['Time']\n",
    "    \n",
    "    # New classifier trace\n",
    "    new_Classifier_data_Labels_Trace = hv.Curve((time, new_classifer_labels), label='New Classifier').opts(line_dash='dashed')\n",
    "\n",
    "    return threshold_line * new_Classifier_data_Labels_Trace\n",
    "\n",
    "# Plot labels on top of the smoothed signal\n",
    "#LFP_Data['raw_LFP_Data']['rescaled_Data_Labels'] = LFP_Data['raw_LFP_Data']['Data_Labels'] * 5.0e-7\n",
    "LFP_Data['raw_LFP_Data']['rescaled_Data_Labels'] = LFP_Data['raw_LFP_Data']['Data_Labels'] * 1.25e-5\n",
    "\n",
    "# Signal envelope plot - \n",
    "signal_Envelope_LFP_Trace = hv.Curve(LFP_Data['raw_LFP_Data'], 'Time', 'signal_Envelope', label='Smoothed Signal')\n",
    "\n",
    "# Stream for detecting double-clicks\n",
    "click_Stream = hv.streams.DoubleTap(source=signal_Envelope_LFP_Trace, x=-10, y=-10, transient=True)\n",
    "\n",
    "# Data labels as a curve\n",
    "rescaled_data_Labels_Trace = hv.Curve(LFP_Data['raw_LFP_Data'], 'Time', 'rescaled_Data_Labels', label='True Labels').opts(line_dash='dashed')\n",
    "\n",
    "# Function definition for marking the region of interest\n",
    "\n",
    "# Highlight the threshold as a horizontal line\n",
    "new_classifier_threshold_line = hv.HLine(ROC_selected_threshold)\n",
    "\n",
    "# Calculate the output of the classifier with the selected threshold\n",
    "new_classifer_labels = np.zeros(len(LFP_Data['raw_LFP_Data']['signal_Envelope']))\n",
    "new_classifier_positive_classification_ids = np.where(LFP_Data['raw_LFP_Data']['signal_Envelope'] > ROC_selected_threshold)[0]\n",
    "new_classifer_labels[new_classifier_positive_classification_ids] = 1 * np.max(LFP_Data['raw_LFP_Data']['rescaled_Data_Labels'])\n",
    "\n",
    "# New classifier trace\n",
    "new_Classifier_data_Labels_Trace = hv.Curve((LFP_Data['raw_LFP_Data']['Time'], new_classifer_labels), label='New Classifier').opts(line_dash='dashed')\n",
    "\n",
    "new_Classifier_Traces = (new_classifier_threshold_line * new_Classifier_data_Labels_Trace)\n",
    "\n",
    "# Define a dynamic map for highlighting the bounds of the region of interest\n",
    "classifier_Threshold_dmap = hv.DynamicMap(mark_Threshold, streams=[click_Stream])\n",
    "\n",
    "#threshold_figure_layout = (signal_Envelope_LFP_Trace * rescaled_data_Labels_Trace * new_Classifier_Traces).opts(fontscale=1.2, title=\"Predicted Classifier Output ({:.3e} V Threshold)\".format(ROC_selected_threshold), ylabel='Voltage', ylim=(-0.1e-7, 5.1e-7))\n",
    "threshold_figure_layout = (signal_Envelope_LFP_Trace * rescaled_data_Labels_Trace * new_Classifier_Traces).opts(fontscale=1.2, title=\"Predicted Classifier Output ({:.3e} V Threshold)\".format(ROC_selected_threshold), ylabel='Voltage', ylim=(-0.1e-8, 1.3e-5))\n",
    "threshold_figure_layout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3745dd01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
